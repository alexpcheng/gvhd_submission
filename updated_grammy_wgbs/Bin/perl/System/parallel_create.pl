#!/usr/bin/perl

use strict;
use File::Copy;
use File::Basename;
use POSIX qw(ceil floor);

require "$ENV{PERL_HOME}/Lib/load_args.pl";
require "$ENV{PERL_HOME}/Sequence/sequence_helpers.pl";

if ($ARGV[0] eq "--help")
{
  print STDOUT <DATA>;
  exit;
}

my %args = load_args(\@ARGV);

my $n_processes = get_arg("n", 10, \%args);
my $split_file  = get_arg("s", "", \%args);
my $copy_file   = get_arg("copy", "", \%args);
my $makefile    = get_arg("m", "Makefile", \%args);
my $command     = get_arg("c", "make parallel", \%args);
my $rr			= get_arg("rr", 0, \%args);
my $mod			= get_arg("mod", 0, \%args);
my $matters		= get_arg("matters", "", \%args);
my $num_queues	= get_arg("nq", 1, \%args);
my $min_t		= get_arg("min_t", 6, \%args);
my $max_u		= get_arg("max_u", 70, \%args);
my $min_u		= get_arg("min_u", 1, \%args);

## Create directory structure and copy makefile into every directory

mkdir ("Parallel");

for (my $i = 1; $i <= $n_processes; $i++)
{
	mkdir ("Parallel/$i");
	mkdir ("Parallel/$i/Output");
	my $makefile_files = `ls ${makefile}*`;
	for my $file (split(/\s/, $makefile_files))
	{
	   chdir ("Parallel/$i");
	   my $cmd = "ln -s ../../${file} ${file}";
	   print `$cmd`;
	   chdir ("../../");
	}
	if ($copy_file ne "")
	{
		my $cmd = "cp $copy_file Parallel/$i/";
		print `$cmd`;
	}
}

my $totalLines=0;

if ($split_file ne "")
{
	if ($rr)
	{
		print STDERR "\nCutting $split_file into $n_processes files.";
		if ($mod)
		{
			print STDERR "\nWarning: -mod does not work with -rr.\n";
		}
	
		my @file_ref;
		
		## Open all split files
		for (my $i = 1; $i <= $n_processes; $i++)
		{
			open ($file_ref[$i-1], ">Parallel/$i/$split_file") or die ("Could not open Parallel/$i/$split_file: $!\n");
		}
		
		## Open the original file, and split it into destination files
		open (SPLITFILE, "<$split_file") or die ("Could not open split file: $split_file: $!\n");
		
		my $fileNum = 0;
		
		while(<SPLITFILE>)
		{
			chomp;
			print {$file_ref[$fileNum]} "$_\n";
	
			$fileNum = ($fileNum+1) % $n_processes;
			if (!($totalLines++ % 10000)) { print STDERR "."; }
		}
		
		## Close all files
		close SPLITFILE;
		
		for (my $i = 1; $i <= $n_processes; $i++)
		{
			close $file_ref[$i-1];
		}
		print STDERR " Done.\n\n";
	}
	else
	{
		## Read file and split it into directories
		
		$totalLines = `wc -l < $split_file`;
		die "wc failed: $?" if $?;
		chomp($totalLines);
		
		my $lines_per_file = ceil ($totalLines / $n_processes);

		if ($mod)
		{
			while ($lines_per_file % $mod)
			{
				$lines_per_file++;
			}
		}
		
		print STDERR "\nCutting $totalLines lines into $n_processes files. $lines_per_file lines per file.\n\n";
		
		`split -a 5 -l $lines_per_file $split_file TMP__`;
		
		## Move files into directories
		
		my $i = 1;
		my $split_basename = basename ($split_file);
		opendir(BIN, ".") or die "Can't open directory";
		while( defined (my $file = readdir BIN) ) {
			if ($file =~ /^TMP__/)  
			{
				move("$file", "Parallel/$i/$split_basename");
				$i++;
			}
		}
		closedir(BIN);
	}
}

## Generate the command required to start the jobs

my $commands_per_queue = int ($n_processes / $num_queues) + 1;

my $run_command = "";
$command =~ /q\.pl\s+(.*)/;
my $noq_command = $1;
if ($noq_command eq "") {$noq_command = $command; }

for (my $qi = 1; $qi <= $num_queues; $qi++)
{
	open (QUEUE, ">Parallel/queue_commands". $qi . ".txt") || die "Can't open Parallel/queue_commands.txt\n";
	
	for (my $i = ($qi-1)*$commands_per_queue + 1; ($i <= $n_processes) && ($i<=$qi*$commands_per_queue); $i++)
	{
		$run_command .= "\tcd $i; $command; cd ..; \\\n";
		print QUEUE "cd $i; $noq_command\n";
	}
	close QUEUE;
}

my $matters_string = "";
if ($matters)
{
	$matters_string = "-matters $matters";
}

open (MAKEFILE, ">Parallel/Makefile") || die "Can't open Parallel/Makefile\n";				
print MAKEFILE <<EOF;
# This Makefile was automatically generated by parallel_create.pl
#
SHELL = tcsh

run:
$run_command

stats:
	parallel_stats.pl -lines $totalLines $matters_string;
	
collect:
	parallel_collect.pl;

queue:
	make queue1;
	
EOF
for (my $qi = 1; $qi <= $num_queues; $qi++)
{
	print MAKEFILE "queue" . $qi .":\n\tnohup qp.pl -min_t $min_t -max_u $max_u -min_u $min_u -report -rerun -f queue_commands". $qi . ".txt > status" . $qi . ".txt &\n\n";
}

close MAKEFILE;

my $rndnum = int(rand(99999));
my $thePwd = `pwd`;
chomp ($thePwd);
$thePwd .= "/Parallel";

for (my $qi = 1; $qi <= $num_queues; $qi++)
{
	open (JOBFILE, ">Parallel/job_$rndnum" . "_$qi.txt") || die "Can't open jobfile.\n";
	print JOBFILE "cd $thePwd; qp.pl -min_t $min_t -max_u $max_u -min_u $min_u -report -manual -f queue_commands". $qi . ".txt > status" . $qi . ".txt\n\n";
	close JOBFILE;
}

__DATA__

parallel_create.pl <file>

	Creates the directories required for running parallel jobs, and splits the
	given file into those directories. In addition, links the local Makefile to
	the target directories and creates the directory structure:
	
		/Parallel/NN/Output
		
	where NN is 1..n
	

   -n <num>:        Number of processes (directories) to open.
   -s <file>:       Name of the file to split.
   -copy <file>:    Name of file to copy to each directory (not splitting it)
   -m <file>:       Name of makefile to be used (default: Makefile).
   -c <command>:    Command to be executed in each directory (default: make parallel).
   -rr:             Create files by round-robin splitting of file.

   -mod <num>:      Make sure the number of lines in each file is a multiple of <num>. E.g.
                    when splitting a fasta file, provide -mod 2 to make sure the ID and sequence
                    are always in the same file (does not work in -rr mode).

   -matters <file>: In case more than one file is created in Output/ then the given filename
                    is the one that's monitored when parallel_stats is called.
   -nq <num>:       Split to <num> different queues (good for running as different users).

   -min_t <num>
   -max_u <num>
   -min_u <num>:    Parameters for qp.pl -- simply echoed to the makefile.
   
