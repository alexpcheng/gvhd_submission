"""
Pipeline for the metagenomic analysis of bisulfite-treated cell-free DNA.
Originally designed by Philip Burnham & Iwijn De Vlaminck for untreated cell-
free DNA. Adapted for bisulfite-treated cell-free DNA by Alexandre Pellan Cheng.
"""

################################################################################
# Config file and setting parameters
################################################################################
configfile: 'config.yaml'
################################################################################
# CLUSTER USED
################################################################################
CLUSTER = config['CLUSTER']
################################################################################
# File locations
################################################################################
ADAPTOR_SEQUENCES = CLUSTER + config['ADAPTOR_SEQUENCES']
METHREF= CLUSTER + config['METHREF']
BWA_HG19= CLUSTER + config['BWA_HG19']
phiXREF= CLUSTER + config['phiXREF']
################################################################################
# Software paths
################################################################################
FLASH = config['FLASH']
BBDUK = CLUSTER + config['BBDUK']
FILTERBYNAME = CLUSTER + config['FILTERBYNAME']
BISMARK = CLUSTER + config['BISMARK']
INTERLEAVE = CLUSTER + config['INTERLEAVE']
HSBLASTN=CLUSTER + config['HSBLASTN']
GRAMMY_RDT = CLUSTER + config['GRAMMY_RDT']
GRAMMY_PRE = CLUSTER + config['GRAMMY_PRE']
GRAMMY_EM =CLUSTER + config['GRAMMY_EM']
GRAMMY_POST =CLUSTER + config['GRAMMY_POST']
GRAMMY_REF_FASTA = CLUSTER + config['GRAMMY_REF_FASTA']
################################################################################
# Variables
################################################################################
CHROMO_SIZES=CLUSTER+config['CHROMO_SIZES']
################################################################################
# Threads
################################################################################
trim_threads=2
host_alignment_threads=10
phiX_alignment_threads=2
blast_threads=8
filter_blast_threads = 1
################################################################################
# RULES
################################################################################
rule all:
	input:
		# THINGS TO ADD: using super dedupe or BBTools' dedupe.sh to remove duplicates.
		expand('sample_output/blast/{conversion}/{sample}.outfmt6', conversion=['CT', 'GA'], sample=config['SAMPLES']),
		expand('sample_output/blast/tblat0/{sample}.tblat.0', sample=config['SAMPLES']),
		expand('sample_output/grammy/{sample}/{sample}.grammy.tab', sample=config['SAMPLES']),
		#expand('databases/viruses/{virus}.fa', virus=config['VIRUSES']),
		#expand('databases/viruses_merged/all.fa'),
		#'test'

################################################################################
# FastQ file processing
# Steps include tagging, trimming and merging fastQ files for alignment
################################################################################
rule trim:
	input:
		r1 = CLUSTER + config['DATA'] +'samples/{sample}_R1.fastq.gz',
		r2 = CLUSTER + config['DATA'] +'samples/{sample}_R2.fastq.gz'
	output:
		r1p = temp('sample_output/{sample}_trim_R1.fastq'),
		r2p = temp('sample_output/{sample}_trim_R2.fastq'),
		r1u = temp('sample_output/{sample}_unpaired_R1.fastq'),
		r2u = temp('sample_output/{sample}_unpaired_R2.fastq')
	threads: trim_threads
	log: 'logs/clip/{sample}.trim.log'
	shell:
		"""
		{BBDUK} in1={input.r1} \
				in2={input.r2} \
				out1={output.r1p} \
				out2={output.r2p} \
				outm1={output.r1u} \
				outm2={output.r2u} \
				-Xmx1g -threads={threads} \
             	ref={ADAPTOR_SEQUENCES} \
				trd=t \
             	tbo tpe &>{log}
		"""

rule merge:
	input:
		r1p = 'sample_output/{sample}_trim_R1.fastq',
		r2p = 'sample_output/{sample}_trim_R2.fastq',
		r1u = 'sample_output/{sample}_unpaired_R1.fastq',
		r2u = 'sample_output/{sample}_unpaired_R2.fastq'
	output:
		flash_combined = temp('sample_output/{sample}.merged.extendedFrags.fastq'),
		unpaired = temp('sample_output/{sample}.merged.unpaired.fastq'),
		flash_R1 = temp('sample_output/{sample}_merged_R1.fastq'),
		flash_R2 = temp('sample_output/{sample}_merged_R2.fastq'),
		flash_hist = temp('sample_output/{sample}.merged.hist'),
		flash_histogram = temp('sample_output/{sample}.merged.histogram')
	log: 'logs/merge/{sample}/{sample}.merge.log'
	params:
		outdir = 'sample_output/'
	threads: 10
	shell:
		"""
		({FLASH} -t {threads} -m 10 {input.r1p} {input.r2p} -d {params.outdir} -o {wildcards.sample}.merged) &>{log}
		mv {params.outdir}/{wildcards.sample}.merged.notCombined_1.fastq {output.flash_R1}
		mv {params.outdir}/{wildcards.sample}.merged.notCombined_2.fastq {output.flash_R2}
		cat {output.flash_combined} {input.r1u} {input.r2u} > {output.unpaired}
		"""

rule PE_host:
	input:
		flash_R1 = 'sample_output/{sample}_merged_R1.fastq',
		flash_R2 = 'sample_output/{sample}_merged_R2.fastq'
	output:
		pe_bam = 'sample_output/host_pe_alignment/{sample}_pe.bam',
		unmapped_R1 = 'sample_output/host_pe_unmapped/{sample}_pe_unmapped_R1.fastq.gz',
		unmapped_R2 = 'sample_output/host_pe_unmapped/{sample}_pe_unmapped_R2.fastq.gz'
	threads: host_alignment_threads
	params:
		outdir = 'sample_output/host_pe_alignment/'
	log: 'logs/pe_alignment/{sample}.log'
	shell:
		"""
		{BISMARK} --genome {METHREF} \
					--parallel {threads} \
					--quiet \
					--unmapped \
					-o {params.outdir} \
					-1 {input.flash_R1} \
					-2 {input.flash_R2}
		mv {params.outdir}{wildcards.sample}_merged_R1_bismark_bt2_pe.bam {output.pe_bam}
		mv {params.outdir}{wildcards.sample}_merged_R1_bismark_bt2_PE_report.txt {log}

		mv {params.outdir}{wildcards.sample}_merged_R1.fastq_unmapped_reads_1.fq.gz {output.unmapped_R1}
		mv {params.outdir}{wildcards.sample}_merged_R2.fastq_unmapped_reads_2.fq.gz {output.unmapped_R2}
		"""

rule SE_host:
	input:
		unpaired = 'sample_output/{sample}.merged.unpaired.fastq'
	output:
		se_bam = 'sample_output/host_se_alignment/{sample}_se.bam',
		unmapped_se = 'sample_output/host_se_unmapped/{sample}_se_unmapped.fastq.gz'
	threads: host_alignment_threads
	params:
		outdir = 'sample_output/host_se_alignment/'
	log: 'logs/se_alignment/{sample}.log'
	shell:
		"""
		{BISMARK} --genome {METHREF} \
					--parallel {threads} \
					--quiet \
					--unmapped \
					-o {params.outdir} \
					{input.unpaired}

		mv {params.outdir}{wildcards.sample}.merged.unpaired_bismark_bt2.bam {output.se_bam}
		mv {params.outdir}{wildcards.sample}.merged.unpaired_bismark_bt2_SE_report.txt {log}
		mv {params.outdir}{wildcards.sample}.merged.unpaired.fastq_unmapped_reads.fq.gz {output.unmapped_se}
		"""

rule interleaving_for_bwa: # This interleaving uses BBTool's reformat, because it can handle .gz files and our input files do not contain orphans
	input:
		unmapped_se = 'sample_output/host_se_unmapped/{sample}_se_unmapped.fastq.gz',
		unmapped_pe_r1 = 'sample_output/host_pe_unmapped/{sample}_pe_unmapped_R1.fastq.gz',
		unmapped_pe_r2 = 'sample_output/host_pe_unmapped/{sample}_pe_unmapped_R2.fastq.gz'
	output:
		interleaved = temp('sample_output/{sample}.nonhost.interleaved.fq.qz'),
		inter_and_unpaired = temp('sample_output/{sample}.nonhost.inter_and_unpaired.fastq.gz')
	shell:
		"""
		{INTERLEAVE} in={input.unmapped_pe_r1} in2={input.unmapped_pe_r2} out=stdout.fq | gzip > {output.interleaved}
		cat {output.interleaved} {input.unmapped_se} > {output.inter_and_unpaired}
		"""

rule phiX_align:
	input:
		inter_and_unpaired = 'sample_output/{sample}.nonhost.inter_and_unpaired.fastq.gz'
	output:
		bam = 'sample_output/phiX_alignment/{sample}.bam',
		paired_fq_r1 = temp('sample_output/phiX_alignment/{sample}.nonhost.nonphix_R1.fq'),
		paired_fq_r2 = temp('sample_output/phiX_alignment/{sample}.nonhost.nonphix_R2.fq'),
		unpaired_fq = temp('sample_output/phiX_alignment/{sample}.nonhost.nonphix_unpaired.fq'),
		tagged_r1 =temp('sample_output/phiX_alignment/{sample}.nonhost.nonphix.tagged_R1.fq'),
		tagged_r2 =temp('sample_output/phiX_alignment/{sample}.nonhost.nonphix.tagged_R2.fq'),
		tagged_un =temp('sample_output/phiX_alignment/{sample}.nonhost.nonphix.tagged_unpaired.fq')
	log: 'logs/phix/{sample}.log'
	threads: phiX_alignment_threads
	shell:
		"""
		(bwa mem -p -t {threads} {phiXREF} {input.inter_and_unpaired} | samtools sort -@ {threads} -n -o {output.bam} -) &>{log}
		samtools view -@ {threads} -h -b -f 0x000D {output.bam} | bedtools bamtofastq -i - -fq {output.paired_fq_r1} -fq2 {output.paired_fq_r2}
		samtools view -@ {threads} -h -b -F 0x0001 -f 0x0004 {output.bam} | bedtools bamtofastq -i - -fq {output.unpaired_fq}

		cat {output.paired_fq_r1} | Bin/fastq_addstr.pl -s "-1" > {output.tagged_r1}
		cat {output.paired_fq_r2} | Bin/fastq_addstr.pl -s "-2" > {output.tagged_r2}
		cat {output.unpaired_fq} | Bin/fastq_addstr.pl -s "-C" > {output.tagged_un}
		"""

rule alignment_statistics:
	input:
		se_bam = 'sample_output/host_se_alignment/{sample}_se.bam',
		pe_bam = 'sample_output/host_pe_alignment/{sample}_pe.bam'
	output:
		merged_bam = temp('sample_output/{sample}_merged.bam'),
		merged_bai = temp('sample_output/{sample}_merged.bam.bai'),
		pe_bam_sorted = temp('sample_output/{sample}_pe_sorted.bam'),
		se_bam_sorted = temp('sample_output/{sample}_se_sorted.bam'),
		stat = 'sample_output/statistics/{sample}_stats.align.tab'
	threads: 5
	params:
		chr='chr21'
	shell:
		"""
		samtools sort -@ {threads} {input.pe_bam} -o {output.pe_bam_sorted}
		samtools sort -@ {threads} {input.se_bam} -o {output.se_bam_sorted}
		samtools merge {output.merged_bam} {output.pe_bam_sorted} {output.se_bam_sorted}
		samtools index {output.merged_bam}
		bash Bin/coverage_calc.sh {output.merged_bam} {params.chr} {wildcards.sample} {CHROMO_SIZES} >> {output.stat}
		"""

rule fastq_to_fasta:
	input:
		tagged_r1 ='sample_output/phiX_alignment/{sample}.nonhost.nonphix.tagged_R1.fq',
		tagged_r2 ='sample_output/phiX_alignment/{sample}.nonhost.nonphix.tagged_R2.fq',
		tagged_un ='sample_output/phiX_alignment/{sample}.nonhost.nonphix.tagged_unpaired.fq'
	output:
		nonhumanfa = 'sample_output/nonhuman_fasta/{sample}.fa'
	shell:
		"""
		cat {input.tagged_r1} {input.tagged_r2} {input.tagged_un} | fastq_to_fasta -Q33 -i - -o {output.nonhumanfa}
		"""

rule hs_blastn:
	input:
		nonhumanfa = 'sample_output/nonhuman_fasta/{sample}.fa',
		db = 'databases/blast/{conversion}_conversion/NCBIGenomes06_{conversion}.fna',
		gi_to_taxid = 'databases/blast/NCBIGenomes06.gis.taxids'
	output:
		converted_fa = temp('sample_output/{sample}.{conversion}.fa'),
		blast_outfmt6 = 'sample_output/blast/{conversion}/{sample}.outfmt6'
	threads: blast_threads
	shell:
		"""
		python Bin/insilico_conversion.py {input.nonhumanfa} {output.converted_fa} {wildcards.conversion}
		{HSBLASTN} align -query {output.converted_fa} \
                        -db {input.db} \
                        -evalue 0.0001 \
                        -perc_identity 95 \
                        -num_threads {threads} \
                        -outfmt 6 | python Bin/get_taxid_filter_strand.py {output.blast_outfmt6} {input.gi_to_taxid} {wildcards.conversion}
		"""

rule filter_blast:
	input:
		blast_outfmt6_CT = 'sample_output/blast/CT/{sample}.outfmt6',
		blast_outfmt6_GA = 'sample_output/blast/GA/{sample}.outfmt6'
	output:
		blast_outfmt6_CTGA = temp('sample_output/blast/{sample}.outfmt6.CTGA'),
		tblat0 = 'sample_output/blast/tblat0/{sample}.tblat.0',
		tblat1 = 'sample_output/grammy/{sample}/{sample}.tblat.1'
	threads: filter_blast_threads
	shell:
		"""
		cat {input.blast_outfmt6_CT} {input.blast_outfmt6_GA} > {output.blast_outfmt6_CTGA}
		python Bin/filter_blast.py {output.blast_outfmt6_CTGA} {output.tblat0}
		python Bin/remove-double-counts-from-blast_apc.py {output.tblat0} {output.tblat1}
		"""

rule grammy:
	input:
		nonhumanfa = 'sample_output/nonhuman_fasta/{sample}.fa',
		tblat1 = 'sample_output/grammy/{sample}/{sample}.tblat.1'
	output:
		nonhumanfa_gz = temp('sample_output/grammy/{sample}/{sample}.fa.gz'),
		nonhumanfasta_gz = temp('sample_output/grammy/{sample}/{sample}.fasta.gz'),
		rdt = 'sample_output/grammy/{sample}/{sample}.rdt',
		mtx = 'sample_output/grammy/{sample}/{sample}.mtx',
		lld = 'sample_output/grammy/{sample}/{sample}.lld',
		btp = 'sample_output/grammy/{sample}/{sample}.btp',
		est = 'sample_output/grammy/{sample}/{sample}.est',
		gra = 'sample_output/grammy/{sample}/{sample}.gra',
		avl = 'sample_output/grammy/{sample}/{sample}.avl'
	shell:
		"""
		cat {input.nonhumanfa} | sed 's/\/1-1/-1/g' |  sed 's/\/2-2/-2/g' | gzip -1 > {output.nonhumanfa_gz}
		cd sample_output/grammy/{wildcards.sample}
		python2.7 {GRAMMY_RDT} -t illumina . .
		python2.7 {GRAMMY_PRE} -q "40,75,-5" {wildcards.sample} {GRAMMY_REF_FASTA}
		python2.7 {GRAMMY_EM} -c L -b 5 -t .00001 -n 100 {wildcards.sample}.mtx
		python2.7 {GRAMMY_POST} {wildcards.sample}.est {GRAMMY_REF_FASTA} {wildcards.sample}.btp
		cd ../../../
		"""

rule annotate_grammy:
	input:
		rdt = 'sample_output/grammy/{sample}/{sample}.rdt',
		mtx = 'sample_output/grammy/{sample}/{sample}.mtx',
		lld = 'sample_output/grammy/{sample}/{sample}.lld',
		btp = 'sample_output/grammy/{sample}/{sample}.btp',
		est = 'sample_output/grammy/{sample}/{sample}.est',
		gra = 'sample_output/grammy/{sample}/{sample}.gra',
		avl = 'sample_output/grammy/{sample}/{sample}.avl',
		stat = 'sample_output/statistics/{sample}_stats.align.tab'
	output:
		tab='sample_output/grammy/{sample}/{sample}.tab',
		anno = 'sample_output/grammy/{sample}/{sample}.grammy.tab'
	params:
		DIR='sample_output/',
		DB='grammy/{sample}/',
		LUT='LUTGrammy/taxids_names_lengths_tax.tab'
	shell:
		"""
		PERL_HOME='{CLUSTER}/workdir/apc88/GVHD/updated_grammy_wgbs/Bin/perl'
		export PERL_HOME
		cat {input.gra} \
			| Bin/perl/Lib/transpose.pl \
			| Bin/perl/Lib/filter.pl -c 1 -mins 0 \
			| Bin/perl/Lib/add_column.pl -b -s "{wildcards.sample}" \
			> {output.tab}
		cp {output.tab} WTV
		Rscript Bin/annotate_grammy_apc.R {params.DIR} {params.DB} {wildcards.sample} {params.LUT}
		"""

rule download_virus_fastas:
	output:
		fa = 'databases/viruses/{virus}.fa'
	shell:
		"""
		wget -O {output.fa} 'https://www.ncbi.nlm.nih.gov/search/api/sequence/{wildcards.virus}/?report=fasta'
		"""
rule merge_viruses:
	input:
		expand('databases/viruses/{virus}.fa', virus=config['VIRUSES'])
	output:
		'databases/viruses_merged/all.fa'
	shell:
		"""
		cat {input} > {output}
		/workdir/apc88/GVHD/software/Bismark-0.22.1/bismark_genome_preparation databases/viruses_merged/
		"""

rule virus_hits:
	input:
		expand('sample_output/grammy/{sample}/{sample}.tblat.1', sample=config['SAMPLES'])
	output:
		dynamic('sample_output/viral_reads/{sample}.txt')
	threads: 10
	shell:
		"""
		mkdir -p 'sample_output/viral_reads'
		python Bin/get_viral_reads.py {threads} {input}
		"""

rule virus_fastq:
	input:
		#r1 = CLUSTER + config['DATA'] +'samples/{sample}_R1.fastq.gz',
		#r2 = CLUSTER + config['DATA'] +'samples/{sample}_R2.fastq.gz',
		read_ids = 'sample_output/viral_reads/{sample}.txt'
	output:
		f1 = 'sample_output/viral_fastqs/{sample}_R1.fastq.gz',
		f2 = 'sample_output/viral_fastqs/{sample}_R2.fastq.gz'
	shell:
		"""
		r1=/workdir/apc88/GVHD/Data/samples/{wildcards.sample}_R1.fastq.gz
		r2=/workdir/apc88/GVHD/Data/samples/{wildcards.sample}_R2.fastq.gz
		{FILTERBYNAME} in=$r1 in2=$r2 names={input.read_ids} out={output.f1} out2={output.f2} include=t
		"""

rule trim_map:
	input:
		r1 = 'sample_output/viral_fastqs/{sample}_R1.fastq.gz',
		r2 = 'sample_output/viral_fastqs/{sample}_R2.fastq.gz',
		ref = 'databases/viruses_merged/all.fa'
	output:
		r1p = temp('sample_output/viral_fastqs/{sample}_trim_R1.fastq'),
		r2p = temp('sample_output/viral_fastqs/{sample}_trim_R2.fastq'),
		r1u = temp('sample_output/viral_fastqs/{sample}_unpaired_R1.fastq'),
		r2u = temp('sample_output/viral_fastqs/{sample}_unpaired_R2.fastq'),
		bam = 'sample_output/viral_bams/{sample}.bam'
	params: outdir = 'sample_output/'
	threads: trim_threads
	log: 'logs/clip/{sample}.trim.log'
	shell:
		"""
		mkdir -p sample_output/viral_bams
		{BBDUK} in1={input.r1} \
				in2={input.r2} \
				out1={output.r1p} \
				out2={output.r2p} \
				outm1={output.r1u} \
				outm2={output.r2u} \
				-Xmx1g -threads={threads} \
             	ref={ADAPTOR_SEQUENCES} \
				trd=t \
             	tbo tpe &>{log}

		{BISMARK} --genome databases/viruses_merged \
					--parallel {threads} \
					--quiet \
					-o {params.outdir} \
					-1 {output.r1p} \
					-2 {output.r2p}
		mv {params.outdir}{wildcards.sample}_trim_R1_bismark_bt2_pe.bam {output.bam}
		"""

rule sort_depth:
	input:
		bam = 'sample_output/viral_bams/{sample}.bam'
	output:
		depth = 'sample_output/viral_depth/{sample}.depth'
	shell:
		"""
		samtools sort {input.bam} -o - | samtools depth -aa - > {output.depth}
		"""

rule subset_hits:
	input:
		bam = 'sample_output/viral_bams/{sample}.bam'
		#tblat1 = 'sample_output/grammy/{sample}/{sample}.tblat.1'
	output:
		bis = 'sample_output/concordant_reads/{sample}.bismark',
		blast = 'sample_output/concordant_reads/{sample}.blast',
		merged = 'sample_output/concordant_reads/{sample}.txt'
	params:
		tblat1 = 'sample_output/grammy/{sample}/{sample}.tblat.1'
	shell:
		"""
		python Bin/read_and_contig.py {input.bam} {output.bis} bam
		python Bin/read_and_contig.py {params.tblat1} {output.blast} blast
		Rscript Bin/merge_reads_alignment.R {output.bis} {output.blast} {output.merged} {wildcards.sample}
		"""

rule agg:
	input:
		dynamic('sample_output/concordant_reads/{sample}.txt'),
		dynamic('sample_output/viral_depth/{sample}.depth')
	output:
		test='test'
	shell:
		"""
		touch {output.test}
		"""

#rule filter_blast:
#	input:
#		blast_outfmt6_CT = 'sample_output/blast/CT/{sample}.outfmt6',
#		blast_outfmt6_GA = 'sample_output/blast/GA/{sample}.outfmt6'
#	output:
#		blast_outfmt6_CTGA = temp('sample_output/blast/{sample}.outfmt6.CTGA'),
#		tblat0 = 'sample_output/blast/tblat0/{sample}.tblat.0',
#		tblat_match = 'sample_output/blast/match/{sample}.match.tblat',
#		tblat_combo = 'sample_output/blast/combo/{sample}.combo.tblat'
#	threads: filter_blast_threads
#	shell:
#		"""
#		cat {input.blast_outfmt6_CT} {input.blast_outfmt6_GA} > {output.blast_outfmt6_CTGA}
#		python Bin/filter_blast.py {output.blast_outfmt6_CTGA} {output.tblat0}
#		python Bin/filter_pregrammy_apc.py {output.tblat0} {output.tblat_match} {output.tblat_combo} {threads}
#		"""
